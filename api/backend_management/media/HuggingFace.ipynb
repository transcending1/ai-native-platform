{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76189c24-ddfa-42e2-b23c-b4e4e8ffe9ec",
   "metadata": {},
   "source": [
    "# 1.Hugging FaceÂ¶Ç‰ΩïÂØºÂá∫Âπ∂‰ΩøÁî®Ê®°Âûã "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "052a0859-5cb0-4440-b7c1-6614f9fa8174",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import os\n",
    "os.environ[\"HF_MODEL_REGISTRY\"] = \"https://huggingface.co/namespace/model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "556025b7-eaae-4d83-9b76-26a17c2fff00",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fd308fe3-caa0-461e-b79a-62424a3e1ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103, 100, 58263, 13299, 119, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "encoding = tokenizer(\"We are very happy to show you the ü§ó Transformers library.\")\n",
    "print(encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae2946bb-e94e-438e-9d5f-061377f88502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='nlptown/bert-base-multilingual-uncased-sentiment', vocab_size=105879, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2f53b546-af10-4bf3-8ec1-f75b31127cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] we are very happy to show you the [UNK] transformers library. [SEP]'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(encoding['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53d24b90-484b-4646-980d-c43428028111",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_batch = tokenizer(\n",
    "    [\"We are very happy to show you the ü§ó Transformers library.\", \"We hope you don't hate it.\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=512,\n",
    "    return_tensors=\"pt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e17788ff-5b00-48e6-865c-70ffc6968b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103,   100,\n",
       "         58263, 13299,   119,   102],\n",
       "        [  101, 11312, 18763, 10855, 11530,   112,   162, 39487, 10197,   119,\n",
       "           102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60b3110f-a90a-496c-a56c-a21354d22882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "pt_model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f19a4fd1-392f-415d-8607-016570215b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_outputs = pt_model(**pt_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b6d826e4-3665-4eb0-b09e-003a88802ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0021, 0.0018, 0.0115, 0.2121, 0.7725],\n",
      "        [0.2084, 0.1826, 0.1969, 0.1755, 0.2365]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "pt_predictions = nn.functional.softmax(pt_outputs.logits, dim=-1)\n",
    "print(pt_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "36d7418d-d873-49e2-aa3e-011d3180e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_save_directory = \"./pt_save_pretrained\"\n",
    "tokenizer.save_pretrained(pt_save_directory)\n",
    "pt_model.save_pretrained(pt_save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a8d094-8c0f-4326-8653-236434f24bcf",
   "metadata": {},
   "source": [
    "# 2.Â¶Ç‰ΩïÊääÊ®°ÂûãËΩ¨Êç¢ÊàêONNXÊ†ºÂºè"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76fe7bfc-4517-40cb-9b28-477974579396",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"We are very happy to show you the ü§ó Transformers library.\"\n",
    "input_ids = tokenizer.encode(input_text, add_special_tokens=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "10d18700-a5fd-400e-b0cd-de08fe51e49f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  101, 11312, 10320, 12495, 19308, 10114, 11391, 10855, 10103,   100,\n",
       "         58263, 13299,   119,   102]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "54c477cf-d973-4bcb-8a1e-777aeb687a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "dummy_input = input_ids  # Áî®‰∫éÁîüÊàêONNXÊ®°ÂûãÁöÑÁ§∫‰æãËæìÂÖ•\n",
    "torch.onnx.export(pt_model, dummy_input, \"model.onnx\", input_names=['input_ids'], output_names=['output'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3703f87e-424a-40f6-919d-d332200235d6",
   "metadata": {},
   "source": [
    "# 3.ONNXRuntimeËøêË°åËµ∑Ê®°Âûã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "59ad903d-3b42-4130-af06-cb17dc995746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-2.6222005, -2.7745323, -0.8966625,  2.0137324,  3.306386 ]],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "\n",
    "# Âä†ËΩΩÂØºÂá∫ÁöÑONNXÊ®°Âûã\n",
    "onnx_model = \"model.onnx\"\n",
    "ort_session = onnxruntime.InferenceSession(onnx_model)\n",
    "\n",
    "# ‰ΩøÁî®ONNXÊ®°ÂûãËøõË°åÊé®ÁêÜ\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "output_name = ort_session.get_outputs()[0].name\n",
    "ort_inputs = {input_name: input_ids.numpy()}\n",
    "ort_outs = ort_session.run([output_name], ort_inputs)\n",
    "print(ort_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "149a9ecc-5b80-4a8b-8205-f3423f3db0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Name: input_ids\n",
      "Input Shape: [1, 14]\n",
      "Input Data Type: 7\n",
      "Output Name: output\n",
      "Output Shape: [1, 5]\n",
      "Output Data Type: 1\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "\n",
    "model_path = \"model.onnx\"\n",
    "model = onnx.load(model_path)\n",
    "\n",
    "# Êü•ÊâæÊ®°ÂûãÁöÑËæìÂÖ•‰ø°ÊÅØ\n",
    "input_info = model.graph.input[0]\n",
    "input_name = input_info.name\n",
    "input_shape = [dim.dim_value for dim in input_info.type.tensor_type.shape.dim]\n",
    "input_dtype = input_info.type.tensor_type.elem_type\n",
    "\n",
    "# Êü•ÊâæÊ®°ÂûãÁöÑËæìÂá∫‰ø°ÊÅØ\n",
    "output_info = model.graph.output[0]\n",
    "output_name = output_info.name\n",
    "output_shape = [dim.dim_value for dim in output_info.type.tensor_type.shape.dim]\n",
    "output_dtype = output_info.type.tensor_type.elem_type\n",
    "\n",
    "print(\"Input Name:\", input_name)\n",
    "print(\"Input Shape:\", input_shape)\n",
    "print(\"Input Data Type:\", input_dtype)\n",
    "print(\"Output Name:\", output_name)\n",
    "print(\"Output Shape:\", output_shape)\n",
    "print(\"Output Data Type:\", output_dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a35799-f422-4698-87cf-c7a4527067d1",
   "metadata": {},
   "source": [
    "# 4.ÈÉ®ÁΩ≤TritonÊúçÂä°\n",
    "```shell\n",
    "docker run --gpus=all --rm --net=host -v ${PWD}:/models nvcr.io/nvidia/tritonserver:23.04-py3 triton-export --model=/models/model.onnx --output=/models/model_config.pbtxt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ca2195-47fe-4a74-ad7f-d9ce586898bc",
   "metadata": {},
   "source": [
    "# 4.‰ΩøÁî®ClientÊµãËØïTritonÊúçÂä°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bcad64d-f106-4b3f-9b1f-7c9e97218a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonhttpclient\n",
    "\n",
    "# ÂàõÂª∫TritonÂÆ¢Êà∑Á´Ø\n",
    "triton_client = tritonhttpclient.InferenceServerClient(\"localhost:8000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2a2cf3-a1b7-48cc-8c76-140ec1f64014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.http as httpclient\n",
    "import numpy as np\n",
    "\n",
    "# ÊûÑÂª∫TritonËØ∑Ê±Ç\n",
    "inputs = []\n",
    "inputs.append(httpclient.InferInput('input_ids', [len(input_ids)], \"INT64\"))\n",
    "inputs[0].set_data_from_numpy(input_ids)\n",
    "\n",
    "outputs = []\n",
    "outputs.append(httpclient.InferRequestedOutput('output__0'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
