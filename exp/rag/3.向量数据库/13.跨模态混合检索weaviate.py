#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Weaviateä¸­æ–‡å¤šæ¨¡æ€æ··åˆæ£€ç´¢æ¡ˆä¾‹ - ç›¸äº²åŒ¹é…ç³»ç»Ÿ
========================================

è¿™ä¸ªæ¡ˆä¾‹æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨Weaviateå®ç°ä¸­æ–‡BM25 + å¤šæ¨¡æ€Embeddingæ··åˆæ£€ç´¢
æ”¯æŒä¸­æ–‡åˆ†è¯ã€ç¨€ç–å‘é‡åŒ–å’Œå›¾ç‰‡+æ–‡æœ¬çš„å¤šæ¨¡æ€embeddingï¼Œæä¾›å®Œæ•´çš„ç›¸äº²åŒ¹é…åŠŸèƒ½
"""

import asyncio
import base64
import os
from typing import List, Dict, Any, Optional

import requests
import weaviate
import weaviate.classes as wvc
from tang_yuan_mlops_sdk.llm.embedding import EmbeddingClient
from weaviate.classes.query import Filter

from settings import embedding_token, WEAVIATE_HOST, WEAVIATE_PORT, WEAVIATE_GRPC_PORT, WEAVIATE_API_KEY, \
    multi_model_embedding_url

# Embeddingé…ç½®
EMBEDDING_BASE_URL = "http://222.186.32.152:10001"
EMBEDDING_TOKEN = embedding_token

# å¤šæ¨¡æ€Embeddingé…ç½®
MULTIMODAL_API_BASE_URL = multi_model_embedding_url

# æµ‹è¯•æ•°æ® - æ·»åŠ å›¾ç‰‡è·¯å¾„
CANDIDATES_DATA = [
    {
        "id": 1,
        "name": "å°é›…",
        "description": "25å²ï¼Œè½¯ä»¶å·¥ç¨‹å¸ˆï¼Œå–œæ¬¢é˜…è¯»å’Œæ—…è¡Œï¼Œæ€§æ ¼æ¸©æŸ”ä½“è´´ï¼Œèº«é«˜165cmï¼Œçˆ±å¥½å¥èº«å’Œç¾é£Ÿï¼Œå¸Œæœ›æ‰¾ä¸€ä¸ªæœ‰ä¸Šè¿›å¿ƒçš„ç”·ç”Ÿ",
        "image": "../2.Embedding/imgs/å°é›….png"
    },
    {
        "id": 2,
        "name": "æ™“ç³",
        "description": "28å²ï¼Œé‡‘èåˆ†æå¸ˆï¼Œçƒ­çˆ±éŸ³ä¹å’Œè‰ºæœ¯ï¼Œæ€§æ ¼å¼€æœ—æ´»æ³¼ï¼Œèº«é«˜168cmï¼Œå–œæ¬¢æˆ·å¤–è¿åŠ¨ï¼Œå¯»æ‰¾å¿—åŒé“åˆçš„ä¼´ä¾£",
        "image": "../2.Embedding/imgs/æ™“ç³.png"
    },
    {
        "id": 3,
        "name": "å°æ…§",
        "description": "26å²ï¼ŒåŒ»ç”Ÿï¼Œæ¸©æ–‡å°”é›…ï¼Œå–œæ¬¢çœ‹ä¹¦å’Œçƒ¹é¥ªï¼Œèº«é«˜162cmï¼Œæ€§æ ¼å†…æ•›ç¨³é‡ï¼Œå¸Œæœ›æ‰¾ä¸€ä¸ªæˆç†Ÿç¨³é‡çš„ç”·ç”Ÿ",
        "image": "../2.Embedding/imgs/å°æ…§.png"
    },
    {
        "id": 4,
        "name": "ä½³ä½³",
        "description": "24å²ï¼Œè®¾è®¡å¸ˆï¼Œå……æ»¡åˆ›æ„å’Œæƒ³è±¡åŠ›ï¼Œå–œæ¬¢ç»˜ç”»å’Œæ‘„å½±ï¼Œèº«é«˜170cmï¼Œæ€§æ ¼ç‹¬ç«‹è‡ªä¿¡ï¼Œå¯»æ‰¾æœ‰è‰ºæœ¯æ°”è´¨çš„ä¼´ä¾£",
        "image": "../2.Embedding/imgs/ä½³ä½³.png"
    },
    {
        "id": 5,
        "name": "å°è’™",
        "description": "27å²ï¼Œæ•™å¸ˆï¼Œå–„è‰¯è€å¿ƒï¼Œå–œæ¬¢å­©å­å’Œå°åŠ¨ç‰©ï¼Œèº«é«˜164cmï¼Œæ€§æ ¼æ¸©å’Œäº²åˆ‡ï¼Œå¸Œæœ›æ‰¾ä¸€ä¸ªæœ‰è´£ä»»å¿ƒçš„ç”·ç”Ÿ",
        "image": "../2.Embedding/imgs/å°è’™.png"
    },
    {
        "id": 6,
        "name": "æ¬£æ¬£",
        "description": "29å²ï¼Œå¾‹å¸ˆï¼Œèªæ˜èƒ½å¹²ï¼Œå–œæ¬¢è¾©è®ºå’Œæ€è€ƒï¼Œèº«é«˜166cmï¼Œæ€§æ ¼åšå¼ºç‹¬ç«‹ï¼Œå¯»æ‰¾æ™ºæ…§å’Œå¹½é»˜çš„ä¼´ä¾£",
        "image": "../2.Embedding/imgs/æ¬£æ¬£.png"
    },
    {
        "id": 7,
        "name": "å°ä¸½",
        "description": "23å²ï¼Œå¸‚åœºè¥é”€ï¼Œå¤–å‘å¥è°ˆï¼Œå–œæ¬¢ç¤¾äº¤å’Œè¿åŠ¨ï¼Œèº«é«˜167cmï¼Œæ€§æ ¼æ´»æ³¼å¼€æœ—ï¼Œå¸Œæœ›æ‰¾ä¸€ä¸ªé˜³å…‰ç§¯æçš„ç”·ç”Ÿ",
        "image": "../2.Embedding/imgs/å°ä¸½.png"
    },
    {
        "id": 8,
        "name": "é›¨æ¡",
        "description": "30å²ï¼Œç ”ç©¶å‘˜ï¼Œåšå­¦æ·±æ€ï¼Œå–œæ¬¢ç§‘å­¦å’Œè¯»ä¹¦ï¼Œèº«é«˜163cmï¼Œæ€§æ ¼å®‰é™å†…æ•›ï¼Œå¯»æ‰¾æœ‰å…±åŒè¯é¢˜çš„çŸ¥è¯†åˆ†å­",
        "image": "../2.Embedding/imgs/é›¨æ¡.png"
    }
]


def encode_image_to_base64(image_path: str) -> str:
    """å°†å›¾ç‰‡æ–‡ä»¶ç¼–ç ä¸ºbase64å­—ç¬¦ä¸²"""
    try:
        with open(image_path, "rb") as image_file:
            return base64.b64encode(image_file.read()).decode('utf-8')
    except Exception as e:
        print(f"âŒ å›¾ç‰‡ç¼–ç å¤±è´¥ {image_path}: {e}")
        return ""


def get_multimodal_embedding(data: List[Dict]) -> List[List[float]]:
    """è°ƒç”¨å¤šæ¨¡æ€APIè·å–embeddingå‘é‡"""
    try:
        response = requests.post(f"{MULTIMODAL_API_BASE_URL}/embed", json={
            "inputs": data
        })
        response.raise_for_status()
        return response.json()['embeddings']
    except Exception as e:
        print(f"âŒ è·å–å¤šæ¨¡æ€embeddingå¤±è´¥: {e}")
        return []


class WeaviateChinesesMultimodalHybridSearch:
    """Weaviateä¸­æ–‡å¤šæ¨¡æ€æ··åˆæ£€ç´¢ç³»ç»Ÿ"""

    def __init__(self):
        """åˆå§‹åŒ–è¿æ¥å’Œé…ç½®"""
        print("ğŸš€ åˆå§‹åŒ–Weaviateä¸­æ–‡å¤šæ¨¡æ€æ··åˆæ£€ç´¢ç³»ç»Ÿ...")

        # åˆå§‹åŒ–Weaviateå®¢æˆ·ç«¯
        self.client = weaviate.connect_to_local(
            host=WEAVIATE_HOST,
            port=WEAVIATE_PORT,
            grpc_port=WEAVIATE_GRPC_PORT,
            headers=None,
            additional_config=None,
            skip_init_checks=False,
            auth_credentials=weaviate.auth.AuthApiKey(api_key=WEAVIATE_API_KEY)
        )

        # åˆå§‹åŒ–æ–‡æœ¬Embeddingå®¢æˆ·ç«¯ï¼ˆç”¨äºçº¯æ–‡æœ¬æŸ¥è¯¢æ—¶çš„å¯¹æ¯”ï¼‰
        self.embedding_client = EmbeddingClient(
            base_url=EMBEDDING_BASE_URL,
            token=EMBEDDING_TOKEN
        )

        self.collection_name = "ChineseMultimodalMatchmaking"
        print("âœ… è¿æ¥åˆå§‹åŒ–å®Œæˆ")

    def __del__(self):
        """æ¸…ç†èµ„æº"""
        if hasattr(self, 'client'):
            self.client.close()

    async def setup_collection(self):
        """åˆ›å»ºæ”¯æŒä¸­æ–‡BM25å’Œå¤šæ¨¡æ€çš„é›†åˆ"""
        print("ğŸ”§ åˆ›å»ºæ”¯æŒä¸­æ–‡BM25å’Œå¤šæ¨¡æ€çš„Weaviateé›†åˆ...")

        # åˆ é™¤å·²å­˜åœ¨çš„é›†åˆ
        if self.client.collections.exists(self.collection_name):
            self.client.collections.delete(self.collection_name)
            print(f"ğŸ—‘ï¸ åˆ é™¤å·²å­˜åœ¨çš„é›†åˆ: {self.collection_name}")

        # åˆ›å»ºé›†åˆé…ç½®ï¼Œæ”¯æŒä¸­æ–‡åˆ†è¯å’ŒBM25
        collection = self.client.collections.create(
            name=self.collection_name,
            properties=[
                wvc.config.Property(
                    name="candidate_id",
                    data_type=wvc.config.DataType.INT,
                    description="å€™é€‰äººID"
                ),
                wvc.config.Property(
                    name="name",
                    data_type=wvc.config.DataType.TEXT,
                    description="å€™é€‰äººå§“å",
                    tokenization=wvc.config.Tokenization.WORD,  # æ”¯æŒåˆ†è¯æœç´¢
                ),
                wvc.config.Property(
                    name="description",
                    data_type=wvc.config.DataType.TEXT,
                    description="å€™é€‰äººæè¿°",
                    tokenization=wvc.config.Tokenization.WORD,  # æ”¯æŒåˆ†è¯æœç´¢
                ),
                wvc.config.Property(
                    name="image_path",
                    data_type=wvc.config.DataType.TEXT,
                    description="å›¾ç‰‡è·¯å¾„"
                ),
                wvc.config.Property(
                    name="age",
                    data_type=wvc.config.DataType.INT,
                    description="å¹´é¾„"
                ),
                wvc.config.Property(
                    name="profession",
                    data_type=wvc.config.DataType.TEXT,
                    description="èŒä¸š"
                ),
                wvc.config.Property(
                    name="height",
                    data_type=wvc.config.DataType.TEXT,
                    description="èº«é«˜"
                ),
                wvc.config.Property(
                    name="personality",
                    data_type=wvc.config.DataType.TEXT,
                    description="æ€§æ ¼ç‰¹ç‚¹"
                ),
                wvc.config.Property(
                    name="hobbies",
                    data_type=wvc.config.DataType.TEXT,
                    description="çˆ±å¥½å…´è¶£"
                ),
                wvc.config.Property(
                    name="requirements",
                    data_type=wvc.config.DataType.TEXT,
                    description="æ‹©å¶è¦æ±‚"
                )
            ],
            # é…ç½®å‘é‡åŒ–å™¨
            vectorizer_config=wvc.config.Configure.Vectorizer.none(),  # ä½¿ç”¨è‡ªå®šä¹‰embedding
            # é…ç½®ç”Ÿæˆå™¨ï¼ˆå¯é€‰ï¼‰
            generative_config=wvc.config.Configure.Generative.openai()
        )

        print(f"âœ… é›†åˆ {self.collection_name} åˆ›å»ºæˆåŠŸ")
        return collection

    def parse_candidate_info(self, candidate: Dict) -> Dict[str, Any]:
        """è§£æå€™é€‰äººä¿¡æ¯ï¼Œæå–ç»“æ„åŒ–å­—æ®µ"""
        description = candidate["description"]

        # ç®€å•çš„ä¿¡æ¯æå–ï¼ˆåœ¨å®é™…åº”ç”¨ä¸­å¯ä»¥ä½¿ç”¨NLPæŠ€æœ¯ï¼‰
        parsed_info = {
            "candidate_id": candidate["id"],
            "name": candidate["name"],
            "description": description,
            "image_path": candidate["image"],
            "age": 25,  # é»˜è®¤å€¼
            "profession": "",
            "height": "",
            "personality": "",
            "hobbies": "",
            "requirements": ""
        }

        # æå–å¹´é¾„
        import re
        age_match = re.search(r'(\d+)å²', description)
        if age_match:
            parsed_info["age"] = int(age_match.group(1))

        # æå–èŒä¸š
        professions = ["è½¯ä»¶å·¥ç¨‹å¸ˆ", "é‡‘èåˆ†æå¸ˆ", "åŒ»ç”Ÿ", "è®¾è®¡å¸ˆ", "æ•™å¸ˆ", "å¾‹å¸ˆ", "å¸‚åœºè¥é”€", "ç ”ç©¶å‘˜"]
        for prof in professions:
            if prof in description:
                parsed_info["profession"] = prof
                break

        # æå–èº«é«˜
        height_match = re.search(r'èº«é«˜(\d+cm)', description)
        if height_match:
            parsed_info["height"] = height_match.group(1)

        # æå–æ€§æ ¼ç‰¹ç‚¹
        personality_keywords = ["æ¸©æŸ”ä½“è´´", "å¼€æœ—æ´»æ³¼", "å†…æ•›ç¨³é‡", "ç‹¬ç«‹è‡ªä¿¡", "æ¸©å’Œäº²åˆ‡", "åšå¼ºç‹¬ç«‹", "æ´»æ³¼å¼€æœ—",
                                "å®‰é™å†…æ•›"]
        personalities = []
        for keyword in personality_keywords:
            if keyword in description:
                personalities.append(keyword)
        parsed_info["personality"] = "ï¼Œ".join(personalities)

        # æå–çˆ±å¥½
        hobby_keywords = ["é˜…è¯»", "æ—…è¡Œ", "å¥èº«", "ç¾é£Ÿ", "éŸ³ä¹", "è‰ºæœ¯", "æˆ·å¤–è¿åŠ¨", "çœ‹ä¹¦", "çƒ¹é¥ª", "ç»˜ç”»", "æ‘„å½±",
                          "ç¤¾äº¤", "è¿åŠ¨", "ç§‘å­¦"]
        hobbies = []
        for hobby in hobby_keywords:
            if hobby in description:
                hobbies.append(hobby)
        parsed_info["hobbies"] = "ï¼Œ".join(hobbies)

        # æå–æ‹©å¶è¦æ±‚
        if "å¸Œæœ›æ‰¾" in description:
            requirements_part = description.split("å¸Œæœ›æ‰¾")[1]
            parsed_info["requirements"] = requirements_part.strip()
        elif "å¯»æ‰¾" in description:
            requirements_part = description.split("å¯»æ‰¾")[1]
            parsed_info["requirements"] = requirements_part.strip()

        return parsed_info

    async def insert_candidates(self, candidates: List[Dict]):
        """æ’å…¥å€™é€‰äººæ•°æ® - ä½¿ç”¨å¤šæ¨¡æ€embedding"""
        print("ğŸ“Š å¼€å§‹æ’å…¥å€™é€‰äººæ•°æ®ï¼ˆå¤šæ¨¡æ€æ¨¡å¼ï¼‰...")

        # è·å–é›†åˆ
        collection = self.client.collections.get(self.collection_name)

        # å‡†å¤‡å¤šæ¨¡æ€æ•°æ®
        multimodal_data = []
        for candidate in candidates:
            image_path = candidate["image"]

            # æ£€æŸ¥å›¾ç‰‡æ˜¯å¦å­˜åœ¨
            if not os.path.exists(image_path):
                print(f"âš ï¸ å›¾ç‰‡ä¸å­˜åœ¨ï¼Œè·³è¿‡: {image_path}")
                continue

            # ç¼–ç å›¾ç‰‡
            image_base64 = encode_image_to_base64(image_path)
            if not image_base64:
                print(f"âš ï¸ å›¾ç‰‡ç¼–ç å¤±è´¥ï¼Œè·³è¿‡: {candidate['name']}")
                continue

            multimodal_data.append({
                "text": candidate["description"],
                "image": f"data:image/png;base64,{image_base64}"
            })

        # æ‰¹é‡è·å–å¤šæ¨¡æ€embedding
        print("ğŸ§  æ­£åœ¨è·å–å¤šæ¨¡æ€embeddingå‘é‡...")
        embeddings = get_multimodal_embedding(multimodal_data)

        if not embeddings:
            print("âŒ è·å–å¤šæ¨¡æ€embeddingå¤±è´¥")
            return

        print(f"âœ… è·å–åˆ° {len(embeddings)} ä¸ªå¤šæ¨¡æ€embeddingå‘é‡ï¼Œç»´åº¦: {len(embeddings[0])}")

        # æ’å…¥æ•°æ®
        valid_candidates = [c for c in candidates if os.path.exists(c["image"])]
        for i, candidate in enumerate(valid_candidates):
            if i >= len(embeddings):
                break

            parsed_info = self.parse_candidate_info(candidate)

            # æ’å…¥æ•°æ®å¹¶æŒ‡å®šå‘é‡
            collection.data.insert(
                properties=parsed_info,
                vector=embeddings[i]
            )

            print(f"âœ… æ’å…¥å€™é€‰äºº: {candidate['name']} (å¤šæ¨¡æ€)")

        print(f"ğŸ‰ æˆåŠŸæ’å…¥ {len(valid_candidates)} ä¸ªå€™é€‰äººæ•°æ®ï¼ˆå¤šæ¨¡æ€ï¼‰")

    async def multimodal_hybrid_search(self, query_text: str, query_image_path: Optional[str] = None,
                                       limit: int = 5, alpha: float = 0.5) -> List[Dict]:
        """
        æ‰§è¡Œå¤šæ¨¡æ€æ··åˆæ£€ç´¢
        
        Args:
            query_text: æŸ¥è¯¢æ–‡æœ¬
            query_image_path: æŸ¥è¯¢å›¾ç‰‡è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            limit: è¿”å›ç»“æœæ•°é‡
            alpha: æ··åˆæƒé‡ï¼Œ0.0=çº¯BM25ï¼Œ1.0=çº¯å‘é‡ï¼Œ0.5=å¹³è¡¡
        
        Returns:
            æ£€ç´¢ç»“æœåˆ—è¡¨
        """
        print(f"\nğŸ” æ‰§è¡Œå¤šæ¨¡æ€æ··åˆæ£€ç´¢:")
        print(f"   ğŸ“ æŸ¥è¯¢æ–‡æœ¬: '{query_text}'")
        if query_image_path:
            print(f"   ğŸ–¼ï¸ æŸ¥è¯¢å›¾ç‰‡: {query_image_path}")
        print(f"   ğŸ“Š æ··åˆå‚æ•°: alpha={alpha} (0.0=çº¯BM25, 1.0=çº¯å‘é‡)")

        # å‡†å¤‡æŸ¥è¯¢æ•°æ®
        if query_image_path and os.path.exists(query_image_path):
            # å¤šæ¨¡æ€æŸ¥è¯¢
            print("ğŸ§  è·å–å¤šæ¨¡æ€æŸ¥è¯¢embedding...")
            image_base64 = encode_image_to_base64(query_image_path)
            if not image_base64:
                print("âŒ æŸ¥è¯¢å›¾ç‰‡ç¼–ç å¤±è´¥")
                return []

            query_data = [{
                "text": query_text,
                "image": f"data:image/png;base64,{image_base64}"
            }]
            query_embeddings = get_multimodal_embedding(query_data)
        else:
            # çº¯æ–‡æœ¬æŸ¥è¯¢ï¼Œä½¿ç”¨æ–‡æœ¬embedding
            print("ğŸ§  è·å–æ–‡æœ¬æŸ¥è¯¢embedding...")
            query_embeddings = await self.embedding_client.get_embeddings([query_text])

        if not query_embeddings:
            print("âŒ è·å–æŸ¥è¯¢embeddingå¤±è´¥")
            return []

        query_vector = query_embeddings[0]

        # è·å–é›†åˆ
        collection = self.client.collections.get(self.collection_name)

        # æ‰§è¡Œæ··åˆæœç´¢
        print("ğŸ” æ‰§è¡Œå¤šæ¨¡æ€æ··åˆæœç´¢...")
        response = collection.query.hybrid(
            query=query_text,  # BM25 query
            vector=query_vector,  # Vector query
            alpha=alpha,  # Hybrid search weight
            limit=limit,
            return_metadata=wvc.query.MetadataQuery(score=True, explain_score=True)
        )

        results = []
        print("\nğŸ“ˆ å¤šæ¨¡æ€æ··åˆæ£€ç´¢ç»“æœ:")
        print("=" * 70)

        for i, obj in enumerate(response.objects, 1):
            result = {
                "rank": i,
                "id": obj.properties["candidate_id"],
                "name": obj.properties["name"],
                "description": obj.properties["description"],
                "image_path": obj.properties["image_path"],
                "age": obj.properties["age"],
                "profession": obj.properties["profession"],
                "height": obj.properties["height"],
                "personality": obj.properties["personality"],
                "hobbies": obj.properties["hobbies"],
                "requirements": obj.properties["requirements"],
                "score": obj.metadata.score,
                "explain_score": obj.metadata.explain_score if hasattr(obj.metadata, 'explain_score') else None
            }

            results.append(result)

            # è¯¦ç»†è¾“å‡º
            print(f"æ’å {i}: {result['name']}")
            print(f"  ğŸ“Š ç»¼åˆå¾—åˆ†: {result['score']:.4f}")
            print(f"  ğŸ–¼ï¸ å›¾ç‰‡è·¯å¾„: {result['image_path']}")
            print(f"  ğŸ‘¤ åŸºæœ¬ä¿¡æ¯: {result['age']}å², {result['profession']}, {result['height']}")
            print(f"  ğŸ’ æ€§æ ¼ç‰¹ç‚¹: {result['personality']}")
            print(f"  ğŸ¯ å…´è¶£çˆ±å¥½: {result['hobbies']}")
            print(f"  ğŸ’• æ‹©å¶è¦æ±‚: {result['requirements']}")
            print(f"  ğŸ“ å®Œæ•´æè¿°: {result['description']}")
            if result['explain_score']:
                print(f"  ğŸ” å¾—åˆ†è§£é‡Š: {result['explain_score']}")
            print("-" * 70)

        return results

    async def compare_search_methods(self, query_text: str, query_image_path: Optional[str] = None, limit: int = 5):
        """æ¯”è¾ƒä¸åŒæ£€ç´¢æ–¹æ³•çš„æ•ˆæœï¼ˆæ”¯æŒå¤šæ¨¡æ€ï¼‰"""
        print(f"\nğŸ†š æ¯”è¾ƒä¸åŒæ£€ç´¢æ–¹æ³•:")
        print(f"   ğŸ“ æŸ¥è¯¢æ–‡æœ¬: '{query_text}'")
        if query_image_path:
            print(f"   ğŸ–¼ï¸ æŸ¥è¯¢å›¾ç‰‡: {query_image_path}")
        print("=" * 80)

        # è·å–é›†åˆ
        collection = self.client.collections.get(self.collection_name)

        # å‡†å¤‡æŸ¥è¯¢å‘é‡
        if query_image_path and os.path.exists(query_image_path):
            # å¤šæ¨¡æ€æŸ¥è¯¢
            image_base64 = encode_image_to_base64(query_image_path)
            if image_base64:
                query_data = [{
                    "text": query_text,
                    "image": f"data:image/png;base64,{image_base64}"
                }]
                query_embeddings = get_multimodal_embedding(query_data)
            else:
                query_embeddings = await self.embedding_client.get_embeddings([query_text])
        else:
            # çº¯æ–‡æœ¬æŸ¥è¯¢
            query_embeddings = await self.embedding_client.get_embeddings([query_text])

        if not query_embeddings:
            print("âŒ è·å–æŸ¥è¯¢å‘é‡å¤±è´¥")
            return

        query_vector = query_embeddings[0]

        # 1. çº¯BM25æ£€ç´¢
        print("\n1ï¸âƒ£ çº¯BM25æ£€ç´¢ (alpha=0.0)")
        print("-" * 40)
        bm25_results = collection.query.hybrid(
            query=query_text,
            vector=query_vector,
            alpha=0.0,  # çº¯BM25
            limit=limit,
            return_metadata=wvc.query.MetadataQuery(score=True)
        )

        for i, obj in enumerate(bm25_results.objects, 1):
            print(f"  {i}. {obj.properties['name']} (BM25å¾—åˆ†: {obj.metadata.score:.4f})")

        # 2. çº¯å‘é‡æ£€ç´¢
        print("\n2ï¸âƒ£ çº¯å‘é‡æ£€ç´¢ (alpha=1.0)")
        print("-" * 40)
        vector_results = collection.query.hybrid(
            query=query_text,
            vector=query_vector,
            alpha=1.0,  # çº¯å‘é‡
            limit=limit,
            return_metadata=wvc.query.MetadataQuery(score=True)
        )

        for i, obj in enumerate(vector_results.objects, 1):
            print(f"  {i}. {obj.properties['name']} (å‘é‡å¾—åˆ†: {obj.metadata.score:.4f})")

        # 3. æ··åˆæ£€ç´¢
        print("\n3ï¸âƒ£ æ··åˆæ£€ç´¢ (alpha=0.5)")
        print("-" * 40)
        hybrid_results = collection.query.hybrid(
            query=query_text,
            vector=query_vector,
            alpha=0.5,  # å¹³è¡¡æ··åˆ
            limit=limit,
            return_metadata=wvc.query.MetadataQuery(score=True)
        )

        for i, obj in enumerate(hybrid_results.objects, 1):
            print(f"  {i}. {obj.properties['name']} (æ··åˆå¾—åˆ†: {obj.metadata.score:.4f})")

        # 4. æƒé‡åå‘BM25çš„æ··åˆæ£€ç´¢
        print("\n4ï¸âƒ£ åå‘BM25çš„æ··åˆæ£€ç´¢ (alpha=0.2)")
        print("-" * 40)
        bm25_heavy_results = collection.query.hybrid(
            query=query_text,
            vector=query_vector,
            alpha=0.2,  # åå‘BM25
            limit=limit,
            return_metadata=wvc.query.MetadataQuery(score=True)
        )

        for i, obj in enumerate(bm25_heavy_results.objects, 1):
            print(f"  {i}. {obj.properties['name']} (BM25æƒé‡æ··åˆå¾—åˆ†: {obj.metadata.score:.4f})")

        # 5. æƒé‡åå‘å‘é‡çš„æ··åˆæ£€ç´¢
        print("\n5ï¸âƒ£ åå‘å‘é‡çš„æ··åˆæ£€ç´¢ (alpha=0.8)")
        print("-" * 40)
        vector_heavy_results = collection.query.hybrid(
            query=query_text,
            vector=query_vector,
            alpha=0.8,  # åå‘å‘é‡
            limit=limit,
            return_metadata=wvc.query.MetadataQuery(score=True)
        )

        for i, obj in enumerate(vector_heavy_results.objects, 1):
            print(f"  {i}. {obj.properties['name']} (å‘é‡æƒé‡æ··åˆå¾—åˆ†: {obj.metadata.score:.4f})")

        # 6. å¤šæ¨¡æ€å¯¹æ¯”ï¼ˆå¦‚æœæœ‰å›¾ç‰‡ï¼‰
        if query_image_path and os.path.exists(query_image_path):
            print("\n6ï¸âƒ£ å¤šæ¨¡æ€å‘é‡ vs çº¯æ–‡æœ¬å‘é‡å¯¹æ¯”")
            print("-" * 40)

            # çº¯æ–‡æœ¬å‘é‡æ£€ç´¢
            text_embeddings = await self.embedding_client.get_embeddings([query_text])
            if text_embeddings:
                text_vector_results = collection.query.hybrid(
                    query=query_text,
                    vector=text_embeddings[0],
                    alpha=0.7,  # åå‘å‘é‡
                    limit=3,
                    return_metadata=wvc.query.MetadataQuery(score=True)
                )

                print("  çº¯æ–‡æœ¬å‘é‡ç»“æœ:")
                for i, obj in enumerate(text_vector_results.objects, 1):
                    print(f"    {i}. {obj.properties['name']} (æ–‡æœ¬å‘é‡: {obj.metadata.score:.4f})")

                print("  å¤šæ¨¡æ€å‘é‡ç»“æœ:")
                multimodal_results = collection.query.hybrid(
                    query=query_text,
                    vector=query_vector,
                    alpha=0.7,  # åå‘å‘é‡
                    limit=3,
                    return_metadata=wvc.query.MetadataQuery(score=True)
                )

                for i, obj in enumerate(multimodal_results.objects, 1):
                    print(f"    {i}. {obj.properties['name']} (å¤šæ¨¡æ€å‘é‡: {obj.metadata.score:.4f})")

    async def filter_search(self, query_text: str, query_image_path: Optional[str] = None,
                            filters: Optional[Dict] = None, limit: int = 5):
        """å¸¦è¿‡æ»¤æ¡ä»¶çš„å¤šæ¨¡æ€æ£€ç´¢"""
        print(f"\nğŸ¯ æ‰§è¡Œè¿‡æ»¤æ£€ç´¢:")
        print(f"   ğŸ“ æŸ¥è¯¢æ–‡æœ¬: '{query_text}'")
        if query_image_path:
            print(f"   ğŸ–¼ï¸ æŸ¥è¯¢å›¾ç‰‡: {query_image_path}")
        if filters:
            print(f"   ğŸ”§ è¿‡æ»¤æ¡ä»¶: {filters}")

        # å‡†å¤‡æŸ¥è¯¢å‘é‡
        if query_image_path and os.path.exists(query_image_path):
            # å¤šæ¨¡æ€æŸ¥è¯¢
            image_base64 = encode_image_to_base64(query_image_path)
            if image_base64:
                query_data = [{
                    "text": query_text,
                    "image": f"data:image/png;base64,{image_base64}"
                }]
                query_embeddings = get_multimodal_embedding(query_data)
            else:
                query_embeddings = await self.embedding_client.get_embeddings([query_text])
        else:
            # çº¯æ–‡æœ¬æŸ¥è¯¢
            query_embeddings = await self.embedding_client.get_embeddings([query_text])

        if not query_embeddings:
            print("âŒ è·å–æŸ¥è¯¢å‘é‡å¤±è´¥")
            return

        query_vector = query_embeddings[0]

        # è·å–é›†åˆ
        collection = self.client.collections.get(self.collection_name)

        # æ„å»ºwhereè¿‡æ»¤æ¡ä»¶
        where_filter = None
        if filters:
            filter_conditions = []
            if "min_age" in filters:
                filter_conditions.append(Filter.by_property("age").greater_or_equal(filters["min_age"]))
            if "max_age" in filters:
                filter_conditions.append(Filter.by_property("age").less_or_equal(filters["max_age"]))
            if "profession" in filters:
                filter_conditions.append(Filter.by_property("profession").equal(filters["profession"]))

            if filter_conditions:
                if len(filter_conditions) == 1:
                    where_filter = filter_conditions[0]
                else:
                    where_filter = Filter.all_of(filter_conditions)

        # æ‰§è¡Œæœç´¢ - æš‚æ—¶ç®€åŒ–å¤„ç†ï¼Œå…ˆä¸æ”¯æŒè¿‡æ»¤æ¡ä»¶
        if where_filter is not None:
            print("âš ï¸ æ³¨æ„ï¼šå½“å‰ç‰ˆæœ¬çš„æ··åˆæ£€ç´¢æš‚ä¸æ”¯æŒè¿‡æ»¤æ¡ä»¶ï¼Œå°†æ‰§è¡Œä¸å¸¦è¿‡æ»¤çš„æœç´¢")
            print(f"   åŸè¿‡æ»¤æ¡ä»¶: {filters}")

        response = collection.query.hybrid(
            query=query_text,
            vector=query_vector,
            alpha=0.5,
            limit=limit,
            return_metadata=wvc.query.MetadataQuery(score=True)
        )

        print("\nğŸ“ˆ è¿‡æ»¤æ£€ç´¢ç»“æœ:")
        print("=" * 70)

        for i, obj in enumerate(response.objects, 1):
            print(f"æ’å {i}: {obj.properties['name']}")
            print(f"  ğŸ“Š å¾—åˆ†: {obj.metadata.score:.4f}")
            print(f"  ğŸ–¼ï¸ å›¾ç‰‡: {obj.properties['image_path']}")
            print(f"  ğŸ‘¤ ä¿¡æ¯: {obj.properties['age']}å², {obj.properties['profession']}")
            print(f"  ğŸ“ æè¿°: {obj.properties['description']}")
            print("-" * 70)


async def demonstrate_weaviate_multimodal_hybrid_search():
    """æ¼”ç¤ºWeaviateä¸­æ–‡å¤šæ¨¡æ€æ··åˆæ£€ç´¢ç³»ç»Ÿ"""
    print("ğŸŒŸ Weaviateä¸­æ–‡å¤šæ¨¡æ€æ··åˆæ£€ç´¢ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 80)

    # åˆ›å»ºç³»ç»Ÿå®ä¾‹
    system = WeaviateChinesesMultimodalHybridSearch()

    try:
        # 1. è®¾ç½®é›†åˆ
        await system.setup_collection()

        # 2. æ’å…¥æ•°æ®ï¼ˆå¤šæ¨¡æ€ï¼‰
        await system.insert_candidates(CANDIDATES_DATA)

        # 3. åŸºæœ¬å¤šæ¨¡æ€æ··åˆæ£€ç´¢æ¼”ç¤º
        print("\n" + "=" * 80)
        print("ğŸ” åŸºæœ¬å¤šæ¨¡æ€æ··åˆæ£€ç´¢æ¼”ç¤º")
        print("=" * 80)

        text_queries = [
            "å¯»æ‰¾ä¸€ä¸ªæ¸©æŸ”ä½“è´´çš„è½¯ä»¶å·¥ç¨‹å¸ˆ",
            "æ‰¾ä¸€ä¸ªå–œæ¬¢è‰ºæœ¯çš„å¥³ç”Ÿ",
            "å¸Œæœ›æ‰¾ä¸€ä¸ªåšå­¦çš„ä¼´ä¾£",
            "å¯»æ‰¾æœ‰è´£ä»»å¿ƒçš„åŒ»ç”Ÿ"
        ]

        for query in text_queries:
            await system.multimodal_hybrid_search(query, limit=3, alpha=0.5)
            input("\næŒ‰å›è½¦é”®ç»§ç»­ä¸‹ä¸€ä¸ªæŸ¥è¯¢...")

        # 4. å¤šæ¨¡æ€æŸ¥è¯¢æ¼”ç¤ºï¼ˆæ–‡æœ¬+å›¾ç‰‡ï¼‰
        print("\n" + "=" * 80)
        print("ğŸ–¼ï¸ å¤šæ¨¡æ€æŸ¥è¯¢æ¼”ç¤ºï¼ˆæ–‡æœ¬+å›¾ç‰‡åå¥½ï¼‰")
        print("=" * 80)

        # æ£€æŸ¥å‚è€ƒå›¾ç‰‡æ˜¯å¦å­˜åœ¨
        reference_images = [
            "../2.Embedding/to_query_imgs/1.png",
            "../2.Embedding/to_query_imgs/2.png",
            "../2.Embedding/to_query_imgs/3.png"
        ]

        multimodal_queries = [
            ("æˆ‘å¸Œæœ›æ‰¾ä¸€ä¸ªæ´»æ³¼å¼€æœ—çš„å¥³ç”Ÿ", "../2.Embedding/to_query_imgs/1.png"),
            ("å¯»æ‰¾æ¸©æŸ”çŸ¥æ€§çš„ä¼´ä¾£", "../2.Embedding/to_query_imgs/2.png"),
            ("å¸Œæœ›æ‰¾ä¸€ä¸ªæœ‰è‰ºæœ¯æ°”è´¨çš„å¥³ç”Ÿ", "../2.Embedding/to_query_imgs/3.png")
        ]

        for text, image_path in multimodal_queries:
            if os.path.exists(image_path):
                await system.multimodal_hybrid_search(text, image_path, limit=3, alpha=0.6)
            else:
                print(f"âš ï¸ å‚è€ƒå›¾ç‰‡ä¸å­˜åœ¨: {image_path}ï¼Œä½¿ç”¨çº¯æ–‡æœ¬æŸ¥è¯¢")
                await system.multimodal_hybrid_search(text, limit=3, alpha=0.5)
            input("\næŒ‰å›è½¦é”®ç»§ç»­ä¸‹ä¸€ä¸ªæŸ¥è¯¢...")

        # 5. æ¯”è¾ƒä¸åŒæ£€ç´¢æ–¹æ³•ï¼ˆåŒ…å«å¤šæ¨¡æ€å¯¹æ¯”ï¼‰
        print("\n" + "=" * 80)
        print("ğŸ†š ä¸åŒæ£€ç´¢æ–¹æ³•æ¯”è¾ƒï¼ˆå¤šæ¨¡æ€ vs çº¯æ–‡æœ¬ï¼‰")
        print("=" * 80)

        comparison_image = "../2.Embedding/to_query_imgs/1.png"
        if os.path.exists(comparison_image):
            await system.compare_search_methods("æ¸©æŸ”çš„åŒ»ç”Ÿ", comparison_image, limit=3)
        else:
            await system.compare_search_methods("æ¸©æŸ”çš„åŒ»ç”Ÿ", limit=3)
        input("\næŒ‰å›è½¦é”®ç»§ç»­...")

        # 6. è¿‡æ»¤æ£€ç´¢æ¼”ç¤ºï¼ˆå¤šæ¨¡æ€ï¼‰
        print("\n" + "=" * 80)
        print("ğŸ¯ å¤šæ¨¡æ€è¿‡æ»¤æ£€ç´¢æ¼”ç¤º")
        print("=" * 80)

        # å¹´é¾„è¿‡æ»¤ + å¤šæ¨¡æ€
        filter_image = "../2.Embedding/to_query_imgs/2.png"
        if os.path.exists(filter_image):
            await system.filter_search(
                "å¯»æ‰¾ä¼´ä¾£",
                filter_image,
                filters={"min_age": 25, "max_age": 28},
                limit=5
            )
        else:
            await system.filter_search(
                "å¯»æ‰¾ä¼´ä¾£",
                filters={"min_age": 25, "max_age": 28},
                limit=5
            )
        input("\næŒ‰å›è½¦é”®ç»§ç»­...")

        # èŒä¸šè¿‡æ»¤
        await system.filter_search(
            "æ‰¾ä¸€ä¸ªèªæ˜çš„äºº",
            filters={"profession": "åŒ»ç”Ÿ"},
            limit=3
        )

        print("\nğŸ“ å¤šæ¨¡æ€æ¼”ç¤ºæ€»ç»“:")
        print("=" * 70)
        print("âœ… 1. æˆåŠŸé…ç½®Weaviateæ”¯æŒä¸­æ–‡BM25åˆ†è¯")
        print("âœ… 2. å®ç°äº†å¤šæ¨¡æ€Embeddingå‘é‡åŒ–ï¼ˆæ–‡æœ¬+å›¾ç‰‡ï¼‰")
        print("âœ… 3. æ··åˆæ£€ç´¢ç»“åˆäº†BM25å’Œå¤šæ¨¡æ€å‘é‡æœç´¢çš„ä¼˜åŠ¿")
        print("âœ… 4. æ”¯æŒçµæ´»çš„æƒé‡è°ƒæ•´å’Œè¿‡æ»¤æ¡ä»¶")
        print("âœ… 5. æä¾›äº†å¤šæ¨¡æ€ vs çº¯æ–‡æœ¬çš„å¯¹æ¯”åˆ†æ")
        print("âœ… 6. æ”¯æŒå›¾ç‰‡åå¥½çš„ä¸ªæ€§åŒ–åŒ¹é…")
        print("\nğŸ’¡ å¤šæ¨¡æ€ç³»ç»Ÿçš„ä¼˜åŠ¿:")
        print("   ğŸ¯ æ›´ç²¾å‡†çš„è¯­ä¹‰ç†è§£ï¼šå›¾ç‰‡+æ–‡æœ¬åŒé‡ä¿¡æ¯")
        print("   ğŸ–¼ï¸ è§†è§‰åå¥½åŒ¹é…ï¼šæ”¯æŒåŸºäºå¤–è²Œçš„ç›¸ä¼¼åº¦è®¡ç®—")
        print("   ğŸ”„ çµæ´»çš„æŸ¥è¯¢æ¨¡å¼ï¼šçº¯æ–‡æœ¬ã€çº¯å›¾ç‰‡ã€å¤šæ¨¡æ€ä»»æ„ç»„åˆ")
        print("   ğŸ“Š ä¸°å¯Œçš„åŒ¹é…ç»´åº¦ï¼šæ–‡å­—æè¿°+è§†è§‰ç‰¹å¾+BM25å…³é”®è¯")
        print("\nğŸ”§ åœ¨å®é™…åº”ç”¨ä¸­çš„è°ƒä¼˜å»ºè®®:")
        print("   â€¢ alphaå‚æ•°ï¼šå¤šæ¨¡æ€æŸ¥è¯¢å»ºè®®0.6-0.8åå‘å‘é‡")
        print("   â€¢ å›¾ç‰‡è´¨é‡ï¼šç¡®ä¿å€™é€‰äººç…§ç‰‡æ¸…æ™°ä¸”ä¸€è‡´")
        print("   â€¢ æ¨¡å‹é€‰æ‹©ï¼šä½¿ç”¨ä¸“é—¨çš„å¤šæ¨¡æ€embeddingæ¨¡å‹")
        print("   â€¢ æƒé‡å¹³è¡¡ï¼šæ ¹æ®ä¸šåŠ¡åœºæ™¯è°ƒæ•´æ–‡æœ¬ä¸å›¾ç‰‡çš„é‡è¦æ€§")

    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

    finally:
        # æ¸…ç†èµ„æº
        print("\nğŸ§¹ æ¸…ç†èµ„æº...")
        if hasattr(system, 'client'):
            system.client.close()
        print("âœ… èµ„æºæ¸…ç†å®Œæˆ")


if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨Weaviateä¸­æ–‡å¤šæ¨¡æ€æ··åˆæ£€ç´¢æ¼”ç¤º")
    asyncio.run(demonstrate_weaviate_multimodal_hybrid_search())
